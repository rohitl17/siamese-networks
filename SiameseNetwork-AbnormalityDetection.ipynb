{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.densenet import DenseNet121\n",
    "\n",
    "import numpy as np\n",
    "from keras.applications.densenet import DenseNet121, DenseNet169\n",
    "import keras.backend as K\n",
    "import cv2\n",
    "import os\n",
    "from keras.callbacks import LearningRateScheduler,ReduceLROnPlateau,CSVLogger,ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score,classification_report,auc,roc_curve\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = max([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    print (n)\n",
    "    d=0\n",
    "    dn=1\n",
    "#     for d in range(num_classes):\n",
    "    for i in range(n):\n",
    "        z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "        pairs += [[x[z1], x[z2]]]\n",
    "#         inc = random.randrange(1, num_classes)\n",
    "#         dn = (d + inc) % num_classes\n",
    "        z1, z2 = digit_indices[d][i], digit_indices[dn][i%len(digit_indices[dn])]\n",
    "        pairs += [[x[z1], x[z2]]]\n",
    "        labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_base_network(input_shape):\n",
    "#     '''Base network to be shared (eq. to feature extraction).\n",
    "#     '''\n",
    "#     input = Input(shape=input_shape)\n",
    "#     x = Flatten()(input)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     x = Dropout(0.1)(x)\n",
    "#     x = Dense(128, activation='relu')(x)\n",
    "#     return Model(input, x)\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    dense_model = DenseNet121(weights='imagenet', include_top=False,input_shape=(224,224,3),pooling='avg')\n",
    "    preds = Dense(1024,activation='relu')(dense_model.output)\n",
    "    model = Model(dense_model.input,preds)\n",
    "#     model=dense_model\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "def img_standardization(x):\n",
    "    \n",
    "#     x=cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x=x.astype('float16')/255.\n",
    "#     return x\n",
    "    return ((x-imagenet_mean)/imagenet_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fold1=np.load('../Pathology_NoPathology/Good_CSV_with_Good_Labels/x_fold1.npy', mmap_mode='r')\n",
    "y_fold1=np.load('../Pathology_NoPathology/Good_CSV_with_Good_Labels/fold1_labels.npy')\n",
    "\n",
    "x_fold2=np.load('../Pathology_NoPathology/Good_CSV_with_Good_Labels/x_fold2.npy', mmap_mode='r')\n",
    "y_fold2=np.load('../Pathology_NoPathology/Good_CSV_with_Good_Labels/fold2_labels.npy')\n",
    "\n",
    "x_fold3=np.load('../Pathology_NoPathology/Good_CSV_with_Good_Labels/x_fold3.npy', mmap_mode='r')\n",
    "y_fold3=np.load('../Pathology_NoPathology/Good_CSV_with_Good_Labels/fold3_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.concatenate([x_fold2, x_fold3])\n",
    "y_train=np.concatenate([y_fold2, y_fold3])\n",
    "\n",
    "x_val=x_fold1\n",
    "y_val=y_fold1\n",
    "\n",
    "Y_train=to_categorical(y_train, num_classes=2)\n",
    "Y_val=to_categorical(y_val, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.zeros(x_train.shape,dtype='float32')\n",
    "for index in range(x_train.shape[0]):\n",
    "    X_train[index]=img_standardization(x_train[index])\n",
    "    print (index)\n",
    "\n",
    "X_val=np.zeros(x_val.shape,dtype='float32')\n",
    "for index in range(x_val.shape[0]):\n",
    "    X_val[index]=img_standardization(x_val[index])\n",
    "    print (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create training+test positive and negative pairs\n",
    "digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_pairs(X_train, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(y_val == i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_pairs(X_val, digit_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(224,224,3)\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "\n",
    "# encoded_l = model(input_shape)\n",
    "# encoded_r = model(input_shape)\n",
    "    \n",
    "#     # Add a customized layer to compute the absolute difference between the encodings\n",
    "# L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "# L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "\n",
    "# # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "# prediction = Dense(1,activation='sigmoid')(L1_distance)\n",
    "\n",
    "# # Connect the inputs with the outputs\n",
    "# model = Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=Adam(lr=1e-3)\n",
    "model.compile(loss=contrastive_loss, optimizer=adam, metrics=[accuracy])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "        os.path.join('./weights/', 'model1.hdf5'),\n",
    "        monitor='val_loss', mode='min',save_best_only=True, verbose=1, save_weights_only=True)\n",
    "\n",
    "callbacks=([model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=32,\n",
    "          epochs=60,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y), verbose=1, callbacks=callbacks, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./weights/model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]], verbose=1)\n",
    "tr_acc = compute_accuracy(tr_y, y_train_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]], verbose=1)\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (y_train_pred, tr_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Test_templates=[]\n",
    "count=0\n",
    "for idx, i in enumerate(y_train_pred):\n",
    "    if np.around(i)==0 and tr_y[idx]==1:\n",
    "        if i>=0.0 and i<=0.2:\n",
    "            Test_templates.append(tr_pairs[idx, 0])\n",
    "            Test_templates.append(tr_pairs[idx, 1])\n",
    "templates=np.array(Test_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (templates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=np.load('/opt/bucketdata/Users/Rohit/MURA_Dataset/bone_data/HAND/X_test.npy', mmap_mode='r')\n",
    "X_val=np.zeros(x_val.shape,dtype='float32')\n",
    "for index in range(x_val.shape[0]):\n",
    "    X_val[index]=img_standardization(x_val[index])\n",
    "    print (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds=[]\n",
    "for idx, i in enumerate(X_val):\n",
    "    preds=[]\n",
    "    for jdx, j in enumerate(templates[0:1]):\n",
    "        preds.append(model.predict([np.expand_dims(j, axis=0), np.expand_dims(i, axis=0)], verbose=0))\n",
    "    print(idx)\n",
    "    final_preds.append(np.average(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=[]\n",
    "for i in final_preds:\n",
    "    if i>=0.8:\n",
    "        Y_pred.append(1)\n",
    "    else:\n",
    "        Y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_pred=np.argmax(op,axis=1)\n",
    "Y_test=np.argmax(Y_val,axis=-1)\n",
    "# Y_test=Y_val.copy()\n",
    "target_names = ['normal','Pathology']\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print (confusion_matrix(Y_test,Y_pred))\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(Y_test,Y_pred,target_names=target_names))\n",
    "\n",
    "print(\"Kappa score:\")\n",
    "print(cohen_kappa_score(Y_test,Y_pred))\n",
    "\n",
    "# Converting Healthy+other into NonTB cases to calculate ROC\n",
    "y_true=np.array(Y_test)\n",
    "y_true[np.where(y_true==1)]=1\n",
    "y_true[np.where(y_true==2)]=1\n",
    "\n",
    "#Taking probabilities of TB class\n",
    "preds = op[:,1]\n",
    "fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "# ROC curve plot\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.savefig('TB_ROC_curve.png',dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1) 1-way shot\n",
    "Confusion Matrix:\n",
    "[[ 235 1131]\n",
    " [   8   71]]\n",
    "Precision: 0.06\n",
    "Sensitivity: 0.9\n",
    "Specificity: 0.17\n",
    "    \n",
    "2) 10-way shot:\n",
    "Confusion Matrix:\n",
    "[[ 289 1077]\n",
    " [   8   71]]\n",
    "\n",
    "Precision: 0.06\n",
    "Sensitivity: 0.9\n",
    "Specificity: 0.21\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
